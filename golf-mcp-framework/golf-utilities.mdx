---
title: 'Golf Utilities'
description: 'Built-in utilities for elicitation, sampling, and context management in Golf v0.2.0.'
---

Golf v0.2.0 introduces powerful built-in utilities that enhance your tool development experience. These utilities are automatically available in all tools without additional imports and provide seamless integration with the Golf Platform for enhanced telemetry and monitoring.

## Overview

Golf utilities provide three core capabilities:

1. **Elicitation** - Interactive user prompting and input collection
2. **Sampling** - LLM interactions and text generation
3. **Context Management** - Access to FastMCP context and request information

All utilities respect your authentication configuration and provide automatic telemetry when used with the Golf Platform.

## Elicitation Utilities

Elicitation utilities enable your tools to interact with users, collect additional information, and create dynamic conversational experiences.

### Basic Usage

```python
from golf.utils import elicit

async def my_interactive_tool():
    # Simple text prompt
    color = await elicit("What's your favorite color?")
    
    # Use the response in your tool logic
    return {"message": f"Great choice! {color} is a beautiful color."}
```

### Advanced Elicitation

```python
from golf.utils import elicit

async def configuration_tool():
    # Collect multiple pieces of information
    name = await elicit("What's your name?")
    email = await elicit("What's your email address?")
    preferences = await elicit("Any special preferences? (optional)")
    
    # Process and use the collected data
    config = {
        "name": name,
        "email": email,
        "preferences": preferences or "None specified"
    }
    
    return {"configuration": config}
```

### Elicitation with Validation

```python
from golf.utils import elicit

async def age_verification_tool():
    while True:
        age_str = await elicit("Please enter your age:")
        try:
            age = int(age_str)
            if age >= 18:
                break
            else:
                await elicit("You must be 18 or older. Please try again.")
        except ValueError:
            await elicit("Please enter a valid number.")
    
    return {"verified": True, "age": age}
```

## Sampling Utilities

Sampling utilities provide direct access to LLM capabilities within your tools, enabling text generation, analysis, and AI-powered processing.

### Basic Sampling

```python
from golf.utils import sample

async def explanation_tool(topic: str):
    # Generate an explanation using the default model
    explanation = await sample(f"Explain {topic} in simple terms")
    
    return {"topic": topic, "explanation": explanation}
```

### Model-Specific Sampling

```python
from golf.utils import sample

async def analysis_tool(text: str):
    # Use a specific model for analysis
    sentiment = await sample(
        f"Analyze the sentiment of this text: '{text}'. Respond with only: positive, negative, or neutral.",
        model="gpt-4"
    )
    
    summary = await sample(
        f"Summarize this text in one sentence: '{text}'",
        model="gpt-3.5-turbo"
    )
    
    return {
        "original_text": text,
        "sentiment": sentiment.strip(),
        "summary": summary
    }
```

### Advanced Sampling with Parameters

```python
from golf.utils import sample

async def creative_writing_tool(prompt: str, style: str):
    # Advanced sampling with custom parameters
    story = await sample(
        f"Write a short story in {style} style based on: {prompt}",
        model="gpt-4",
        max_tokens=500,
        temperature=0.8
    )
    
    return {
        "prompt": prompt,
        "style": style,
        "story": story
    }
```

## Context Management

Context utilities provide access to FastMCP context, request information, and authentication details.

### Basic Context Access

```python
from golf.utils import get_context

async def context_aware_tool():
    # Get the current FastMCP context
    context = get_context()
    
    # Access request information
    request_id = context.get("request_id")
    client_info = context.get("client_info")
    
    return {
        "request_id": request_id,
        "client": client_info
    }
```

### Authentication Context

```python
from golf.utils import get_context
from golf.auth import get_api_key

async def authenticated_tool():
    # Get context and auth information
    context = get_context()
    api_key = get_api_key()
    
    # Use context for logging or customization
    user_id = context.get("user_id")
    session_id = context.get("session_id")
    
    return {
        "authenticated": bool(api_key),
        "user_id": user_id,
        "session_id": session_id
    }
```

### Request Metadata

```python
from golf.utils import get_context

async def metadata_tool():
    context = get_context()
    
    # Access various metadata
    metadata = {
        "timestamp": context.get("timestamp"),
        "client_version": context.get("client_version"),
        "transport": context.get("transport"),
        "headers": context.get("headers", {})
    }
    
    return {"request_metadata": metadata}
```

## Combined Usage Examples

### Interactive Data Processing

```python
from golf.utils import elicit, sample, get_context

async def intelligent_data_processor():
    # Get context
    context = get_context()
    
    # Elicit data from user
    data = await elicit("Please provide the data you'd like to analyze:")
    analysis_type = await elicit("What type of analysis? (summary, sentiment, classification)")
    
    # Use LLM to process the data
    if analysis_type.lower() == "summary":
        result = await sample(f"Summarize this data: {data}")
    elif analysis_type.lower() == "sentiment":
        result = await sample(f"Analyze sentiment of: {data}")
    else:
        result = await sample(f"Classify this data: {data}")
    
    return {
        "input_data": data,
        "analysis_type": analysis_type,
        "result": result,
        "processed_at": context.get("timestamp")
    }
```

### Conversational Tool

```python
from golf.utils import elicit, sample

async def conversational_assistant():
    # Start a conversation
    user_input = await elicit("Hello! What would you like to talk about?")
    
    # Generate contextual response
    response = await sample(
        f"You are a helpful assistant. The user said: '{user_input}'. "
        f"Respond in a friendly and helpful manner.",
        model="gpt-4"
    )
    
    # Continue the conversation
    follow_up = await elicit(f"{response}\n\nAnything else you'd like to know?")
    
    if follow_up.lower() not in ["no", "nothing", "nope"]:
        final_response = await sample(
            f"The user asked a follow-up: '{follow_up}'. Provide a helpful response.",
            model="gpt-4"
        )
        return {"conversation": [user_input, response, follow_up, final_response]}
    
    return {"conversation": [user_input, response]}
```

## Golf Platform Integration

When used with the Golf Platform (by setting `GOLF_API_KEY`), these utilities provide enhanced capabilities:

### Automatic Telemetry

```python
# Telemetry is automatically captured for all utility usage
from golf.utils import elicit, sample

async def monitored_tool():
    # These operations are automatically traced and monitored
    user_input = await elicit("Enter some text:")
    analysis = await sample(f"Analyze: {user_input}")
    
    return {"analysis": analysis}
```

### Enhanced Error Reporting

```python
from golf.utils import sample, get_context

async def robust_tool():
    try:
        result = await sample("Complex analysis task")
        return {"result": result}
    except Exception as e:
        # Context and error details are automatically captured
        context = get_context()
        return {
            "error": str(e),
            "request_id": context.get("request_id"),
            "occurred_at": context.get("timestamp")
        }
```

## Configuration

Golf utilities can be configured through environment variables:

### Environment Variables

```bash
# Golf Platform integration
GOLF_API_KEY=your-platform-key  # Enables enhanced telemetry

# LLM configuration for sampling
OPENAI_API_KEY=your-openai-key  # For OpenAI models
ANTHROPIC_API_KEY=your-anthropic-key  # For Anthropic models

# Sampling defaults
DEFAULT_MODEL=gpt-4  # Default model for sampling
DEFAULT_MAX_TOKENS=1000  # Default token limit
DEFAULT_TEMPERATURE=0.7  # Default creativity level
```

### Project Configuration

Add utility configuration to your `golf.json`:

```json
{
  "name": "my-project",
  "golf_utilities": {
    "default_model": "gpt-4",
    "elicitation_timeout": 300,
    "sampling_max_tokens": 2000
  }
}
```

## Best Practices

### Performance Optimization

```python
# Cache expensive operations
from golf.utils import sample
import asyncio

async def optimized_tool(items: list):
    # Process items concurrently
    tasks = [
        sample(f"Process item: {item}")
        for item in items
    ]
    
    results = await asyncio.gather(*tasks)
    return {"results": results}
```

### Error Handling

```python
from golf.utils import elicit, sample
import logging

async def robust_tool():
    try:
        user_input = await elicit("Enter your request:")
        if not user_input:
            return {"error": "No input provided"}
            
        result = await sample(f"Process: {user_input}")
        return {"result": result}
        
    except Exception as e:
        logging.error(f"Tool failed: {e}")
        return {"error": "Processing failed", "details": str(e)}
```

### Context Awareness

```python
from golf.utils import get_context, sample

async def context_aware_tool():
    context = get_context()
    
    # Adapt behavior based on context
    client_type = context.get("client_info", {}).get("type")
    
    if client_type == "mobile":
        # Provide shorter responses for mobile clients
        response = await sample("Brief response please", max_tokens=100)
    else:
        # Detailed response for desktop clients
        response = await sample("Detailed response please", max_tokens=500)
    
    return {"response": response, "optimized_for": client_type}
```

Golf utilities transform your tools from simple functions into intelligent, interactive experiences that can adapt to user needs and provide rich, AI-powered functionality.